# -*- coding: utf-8 -*-
"""Water_Quality_Prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1r3AKPf2whpOAdcsiKfmBbs8I5vZvajw_

Importing libraries
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import plotly.express as px 
import seaborn as sns

from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

from sklearn.metrics import accuracy_score, classification_report,confusion_matrix

"""Opening File data set"""

df = pd.read_csv("/content/water_potability.csv")
df.head() # prining first five rows of data

df.describe()

df.info() # type of data it's float,int

df.isnull().sum() # how many data have null values count

plt.figure(figsize=(12,8))
sns.heatmap(df.isnull())  # visuallising where is null values

plt.figure(figsize=(12,8))  # we are correalating hows the one item related with another
sns.heatmap(df.corr(),annot=True)

sns.countplot(x="Potability",data=df) # counting how many potability has zeroes and ones

df["Potability"].value_counts()

# Visulaization Dataset also checking for outliers
fig ,ax =plt.subplots(ncols=5,nrows =2,figsize = (25,20) )

ax = ax.flatten()

index = 0

for col,values in df.items():
    sns.boxplot(y=col,data=df,ax=ax[index])
    index+=1

fig = px.pie(df,names = "Potability",hole =0.4,template = "plotly_dark")
fig.show()

fig = px.scatter(df,x='ph',y='Sulfate',color = "Potability",template ='plotly_dark')
fig.show()

#visulatition of null values
df.isnull().mean().plot.bar(figsize=(10,6))
plt.xlabel("Features")
plt.ylabel("Percentage of Missing values")

"""**Dealing with null values**"""

# filling mean values at null values
df['ph'] = df['ph'].fillna(df['ph'].mean())
df['Sulfate'] = df['Sulfate'].fillna(df['Sulfate'].mean())
df['Trihalomethanes']=df['Trihalomethanes'].fillna(df['Trihalomethanes'].mean())

df.isnull().sum() # we filled with all null values

sns.heatmap(df.isnull())

"""**Data** **Preparation**"""

df.head()

x =df.drop("Potability",axis=1) # we are prpocessing with all the features except Potability
y = df["Potability"]

x.shape , y.shape

scaler = StandardScaler()  
x = scaler.fit_transform(x) # put every data in on same scale
x

"""Taking data for training and testing"""

x_train,x_test,y_train,y_test =train_test_split(x,y,test_size=0.2)

y_test

x_train.shape , x_test.shape # traning data,testing data res

y_train.shape, y_test.shape

"""Model Building : **Logistic Regression Al** """

from sklearn.linear_model import LogisticRegression

# object of LR
model_lr = LogisticRegression()

#Training Model
model_lr.fit(x_train,y_train)

# Making Prediction
pred_lr = model_lr.predict(x_test)

# accuracy score
accuracy_score_lr = accuracy_score(y_test,pred_lr)
accuracy_score_lr*100

#cofusion Matrix
cm1 = confusion_matrix(y_test,pred_lr)
cm1

# plt.figure(figsize=(12,8))
sns.heatmap(cm1)

"""Model Building :  Decision Tree Classifier"""

from sklearn.tree import DecisionTreeClassifier

# creating model object

model_dt = DecisionTreeClassifier(max_depth = 4)

# Training of decision tree
model_dt.fit(x_train,y_train) # (fatures,target)

#Making prediction using decision Tree
pred_dt = model_dt.predict(x_test)

accuracy_score_dt = accuracy_score(y_test,pred_dt)
accuracy_score_dt*100

#confusion matrix
cm2 = confusion_matrix(y_test,pred_dt)
cm2

"""Random Forest Classifiers"""

from sklearn.ensemble import RandomForestClassifier

# create object 
model_rf = RandomForestClassifier()

# Training Model RF
model_rf.fit(x_train,y_train)

# making prediction part
pred_rf = model_rf.predict(x_test)

accuracy_score_rf = accuracy_score(y_test,pred_rf)
accuracy_score_rf*100

"""KNeighbours Classifiers"""

from sklearn.neighbors import KNeighborsClassifier

# create Model object
# model_knn = KNeighborsClassifier()

for i in range(4,15):
  model_knn =KNeighborsClassifier(n_neighbors=i)
  model_knn.fit(x_train,y_train)
  pred_knn = model_knn.predict(x_test)
  accuracy_score_knn = accuracy_score(y_test,pred_knn)
  print(i,accuracy_score_knn)

model_knn =KNeighborsClassifier(n_neighbors=14)
model_knn.fit(x_train,y_train)
pred_knn = model_knn.predict(x_test)
accuracy_score_knn = accuracy_score(y_test,pred_knn)
print(accuracy_score_knn*100)

"""Support Vector Machine"""

from sklearn.svm import SVC

#Createing object
model_svm = SVC(kernel="rbf")

#Model Training
model_svm.fit(x_train,y_train)

# Make Prediction
pred_svm = model_svm.predict(x_test)

accuracy_score_svm = accuracy_score(y_test,pred_svm)
accuracy_score_svm*100